{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T05:11:51.147300Z","iopub.status.busy":"2023-12-04T05:11:51.146921Z","iopub.status.idle":"2023-12-04T05:12:04.288189Z","shell.execute_reply":"2023-12-04T05:12:04.287048Z","shell.execute_reply.started":"2023-12-04T05:11:51.147268Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting peft\n","  Obtaining dependency information for peft from https://files.pythonhosted.org/packages/14/0b/8402305043884c76a9d98e5e924c3f2211c75b02acd5b742e6c45d70506d/peft-0.6.2-py3-none-any.whl.metadata\n","  Downloading peft-0.6.2-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.24.3)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\n","Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.35.0)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\n","Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.24.1)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.0)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->peft) (0.17.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.0.9)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.12.2)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.5.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.8.8)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.14.1)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate>=0.21.0->peft) (2023.10.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Downloading peft-0.6.2-py3-none-any.whl (174 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: peft\n","Successfully installed peft-0.6.2\n"]}],"source":["!pip install peft"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-04T05:12:04.290279Z","iopub.status.busy":"2023-12-04T05:12:04.289968Z","iopub.status.idle":"2023-12-04T05:12:56.916953Z","shell.execute_reply":"2023-12-04T05:12:56.916047Z","shell.execute_reply.started":"2023-12-04T05:12:04.290249Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdineshbond1453\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20231204_051224-cqmbzg0h</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/dineshbond1453/MediVQA/runs/cqmbzg0h' target=\"_blank\">devout-surf-88</a></strong> to <a href='https://wandb.ai/dineshbond1453/MediVQA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/dineshbond1453/MediVQA' target=\"_blank\">https://wandb.ai/dineshbond1453/MediVQA</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/dineshbond1453/MediVQA/runs/cqmbzg0h' target=\"_blank\">https://wandb.ai/dineshbond1453/MediVQA/runs/cqmbzg0h</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dineshbond1453/MediVQA/runs/cqmbzg0h?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7963ea3285e0>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["from torch.utils.data import Dataset\n","from PIL import Image\n","import os\n","from sklearn.metrics import accuracy_score\n","import torch\n","from transformers import BlipForQuestionAnswering, AdamW, AutoProcessor\n","from torch.utils.data import DataLoader\n","from peft import get_peft_model, LoraConfig\n","from tqdm import tqdm\n","import wandb\n","from torchvision import transforms\n","\n","# Login to wandb\n","wandb.login(key=\"11045189c6a87e054bc175e57214d6d03c4d47b3\")\n","\n","# Initialize a wandb run\n","wandb.init(project=\"MediVQA\", entity=\"dineshbond1453\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T05:12:56.919376Z","iopub.status.busy":"2023-12-04T05:12:56.919033Z","iopub.status.idle":"2023-12-04T05:12:56.928510Z","shell.execute_reply":"2023-12-04T05:12:56.927681Z","shell.execute_reply.started":"2023-12-04T05:12:56.919340Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset\n","from PIL import Image\n","import os\n","\n","class VQAMedDataset(Dataset):\n","    def __init__(self, qa_pairs_path, image_dir, transform=None):\n","        \"\"\"\n","        Args:\n","            qa_pairs_path (str): Path to the file containing QA pairs.\n","            image_dir (str): Directory with all the images.\n","            transform (callable, optional): Optional transform to be applied on the image.\n","        \"\"\"\n","        with open(qa_pairs_path, 'r', encoding=\"utf-8\") as f:\n","            lines = f.readlines()\n","            self.data = [line.strip().split('|') for line in lines]\n","\n","        self.image_dir = image_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        image_id, question, answer = self.data[idx]\n","        image_path = os.path.join(self.image_dir, f\"{image_id}.jpg\")\n","        image = Image.open(image_path).convert(\"RGB\")\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, question, answer"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T05:12:56.932145Z","iopub.status.busy":"2023-12-04T05:12:56.931157Z","iopub.status.idle":"2023-12-04T05:12:57.012827Z","shell.execute_reply":"2023-12-04T05:12:57.011822Z","shell.execute_reply.started":"2023-12-04T05:12:56.932109Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(<PIL.Image.Image image mode=RGB size=1024x659>,\n"," 'what kind of image is this?',\n"," 'cta - ct angiography')"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# the path to the training images\n","train_image_dir = \"/kaggle/input/no-val-med/NO_VAL_DATA/Training\"\n","qa_pairs_path = \"/kaggle/input/no-val-med/NO_VAL_DATA/TRAIN.txt\"\n","\n","# Instantiate the dataset (without image transformations for now)\n","sample_dataset = VQAMedDataset(qa_pairs_path, train_image_dir)\n","\n","# Check a sample from the dataset\n","sample_dataset[0]"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T05:12:57.015009Z","iopub.status.busy":"2023-12-04T05:12:57.014150Z","iopub.status.idle":"2023-12-04T05:12:57.027675Z","shell.execute_reply":"2023-12-04T05:12:57.026756Z","shell.execute_reply.started":"2023-12-04T05:12:57.014972Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(<PIL.Image.Image image mode=RGB size=432x709>,\n"," 'is this a noncontrast mri?',\n"," 'no')"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["sample_dataset[3]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T05:12:57.029291Z","iopub.status.busy":"2023-12-04T05:12:57.028952Z","iopub.status.idle":"2023-12-04T05:12:57.038247Z","shell.execute_reply":"2023-12-04T05:12:57.037223Z","shell.execute_reply.started":"2023-12-04T05:12:57.029258Z"},"trusted":true},"outputs":[],"source":["# Custom collate function\n","def vqa_collate(batch):\n","    \"\"\"\n","    Custom collate function for our VQA dataset.\n","    \n","    Args:\n","        batch (list): List of samples fetched from the VQAMedDataset.\n","    \n","    Returns:\n","        tuple: Contains batched images, questions, and answers.\n","    \"\"\"\n","    # Unzip the batch data\n","    images, questions, answers = zip(*batch)\n","    \n","    # Stack images\n","    images = torch.stack(images, 0)\n","    \n","    return images, questions, answers\n","\n","# Transformations for the images\n","transform = transforms.Compose([\n","    transforms.Resize((384, 384)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711]),\n","])"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T05:12:57.040489Z","iopub.status.busy":"2023-12-04T05:12:57.039667Z","iopub.status.idle":"2023-12-04T05:12:57.366860Z","shell.execute_reply":"2023-12-04T05:12:57.365917Z","shell.execute_reply.started":"2023-12-04T05:12:57.040454Z"},"trusted":true},"outputs":[],"source":["# Create the dataset and data loader\n","train_dataset = VQAMedDataset(qa_pairs_path, train_image_dir, transform=transform)\n","data_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=vqa_collate)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T05:12:57.368701Z","iopub.status.busy":"2023-12-04T05:12:57.368266Z","iopub.status.idle":"2023-12-04T05:14:29.966607Z","shell.execute_reply":"2023-12-04T05:14:29.965498Z","shell.execute_reply.started":"2023-12-04T05:12:57.368666Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bbdc1feddee34d848b9cedd6cc5204c9","version_major":2,"version_minor":0},"text/plain":["Downloading config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"727c2933a38f4ad79f80794af5b415e9","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/1.54G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8113e8fbf8447cab218278d0639cb43","version_major":2,"version_minor":0},"text/plain":["Downloading (…)rocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f006ba40923c47d09e1e23e7984e0a6b","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"61d8d07020154f04a7f99263d36968d7","version_major":2,"version_minor":0},"text/plain":["Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a64340e8280c460c8be2105ad3fc436e","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45f92b7aec74464dbad795fc98967600","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Initialize model and optimizer\n","model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\n","processor = AutoProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T05:14:29.968521Z","iopub.status.busy":"2023-12-04T05:14:29.968098Z","iopub.status.idle":"2023-12-04T05:14:29.983290Z","shell.execute_reply":"2023-12-04T05:14:29.982048Z","shell.execute_reply.started":"2023-12-04T05:14:29.968479Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 384672572 || all params: 384672572 || trainable%: 100.0\n"]}],"source":["def print_trainable_parameters(model):\n","    \"\"\"\n","    Prints the number of trainable parameters in the model.\n","    \"\"\"\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n","    )\n","\n","print_trainable_parameters(model)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T05:14:29.988371Z","iopub.status.busy":"2023-12-04T05:14:29.988046Z","iopub.status.idle":"2023-12-04T05:14:34.707685Z","shell.execute_reply":"2023-12-04T05:14:34.706480Z","shell.execute_reply.started":"2023-12-04T05:14:29.988344Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 2359296 || all params: 387031868 || trainable%: 0.6095870120958619\n"]}],"source":["# Define LoRA configuration for the BLIP VQA model\n","config = LoraConfig(\n","    r=16,  # Rank of LoRA, adjust as needed\n","    lora_alpha=32,  # Scaling factor, adjust as needed\n","    lora_dropout=0.1,  # Dropout for LoRA layers, adjust as needed\n","    bias=\"none\",  # Bias configuration for LoRA layers\n","    target_modules=[\"query\", \"value\"]  # Target modules in the Transformer to apply LoRA\n"," )\n","\n","# Acquire the LoRA-adapted model\n","peft_model = get_peft_model(model, config)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","peft_model.to(device)\n","print_trainable_parameters(peft_model)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T05:14:34.709556Z","iopub.status.busy":"2023-12-04T05:14:34.709168Z","iopub.status.idle":"2023-12-04T05:14:34.729336Z","shell.execute_reply":"2023-12-04T05:14:34.728535Z","shell.execute_reply.started":"2023-12-04T05:14:34.709518Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# Initialize processor and tokenizer\n","optimizer = AdamW(peft_model.parameters(), lr=5e-5)\n","tokenizer = processor.tokenizer"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T05:14:34.731491Z","iopub.status.busy":"2023-12-04T05:14:34.730816Z","iopub.status.idle":"2023-12-04T06:32:49.901878Z","shell.execute_reply":"2023-12-04T06:32:49.900840Z","shell.execute_reply.started":"2023-12-04T05:14:34.731456Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/5:   0%|          | 0/1411 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n","Epoch 1/5: 100%|██████████| 1411/1411 [15:49<00:00,  1.49it/s, loss=3.7894]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1: New best model saved with loss 7.6012\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5: 100%|██████████| 1411/1411 [15:35<00:00,  1.51it/s, loss=2.2171]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2: New best model saved with loss 7.1296\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5: 100%|██████████| 1411/1411 [15:30<00:00,  1.52it/s, loss=3.1936]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3: New best model saved with loss 7.0291\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5: 100%|██████████| 1411/1411 [15:32<00:00,  1.51it/s, loss=5.4841]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4: New best model saved with loss 6.9709\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5: 100%|██████████| 1411/1411 [15:30<00:00,  1.52it/s, loss=5.0804]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5: New best model saved with loss 6.9274\n"]}],"source":["best_loss = float('inf')  # Initialize the best loss to a very high value\n","best_model_path = \"best_model.pth\"  # Path where the best model will be saved\n","\n","for epoch in range(5):\n","    progress_bar = tqdm(data_loader, desc=f\"Epoch {epoch + 1}/{5}\")\n","    total_loss = 0\n","    num_batches = 0\n","\n","    for batch in progress_bar:\n","        images, questions, answers = batch\n","\n","        # Tokenize questions and answers\n","        inputs = tokenizer(questions, return_tensors=\"pt\", padding=True, truncation=True)\n","        targets = tokenizer(answers, return_tensors=\"pt\", padding=True, truncation=True)\n","\n","        # Move to device\n","        images = images.to(device)\n","        inputs = {key: val.to(device) for key, val in inputs.items()}\n","        targets = targets[\"input_ids\"].to(device)\n","\n","        # Forward pass\n","        optimizer.zero_grad()\n","        outputs = peft_model(pixel_values=images, input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], labels=targets)\n","        loss = outputs.loss\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Update total loss and batch count\n","        total_loss += loss.item()\n","        num_batches += 1\n","\n","        # Update progress bar\n","        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n","\n","    # Calculate average loss for the epoch\n","    epoch_loss = total_loss / num_batches\n","    wandb.log({'epoch': epoch, 'loss': epoch_loss})\n","\n","    # Save the best model\n","    if epoch_loss < best_loss:\n","        best_loss = epoch_loss\n","        torch.save(peft_model.state_dict(), best_model_path)\n","        print(f\"Epoch {epoch+1}: New best model saved with loss {best_loss:.4f}\")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T06:32:49.903637Z","iopub.status.busy":"2023-12-04T06:32:49.903292Z","iopub.status.idle":"2023-12-04T06:32:49.909075Z","shell.execute_reply":"2023-12-04T06:32:49.908076Z","shell.execute_reply.started":"2023-12-04T06:32:49.903601Z"},"trusted":true},"outputs":[],"source":["# # Save the model locally\n","# save_directory = \"/kaggle/working/\"\n","# peft_model.save_pretrained(save_directory)\n","# tokenizer.save_pretrained(save_directory)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T06:52:41.881949Z","iopub.status.busy":"2023-12-04T06:52:41.881520Z","iopub.status.idle":"2023-12-04T06:52:41.889562Z","shell.execute_reply":"2023-12-04T06:52:41.888565Z","shell.execute_reply.started":"2023-12-04T06:52:41.881915Z"},"trusted":true},"outputs":[],"source":["# Preprocess the Image\n","def preprocess_image(image_path):\n","    image = Image.open(image_path).convert(\"RGB\")\n","    \n","    # Define the transformations: resize the image, convert to tensor, and normalize\n","    transform = transforms.Compose([\n","        transforms.Resize((384, 384)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711]),\n","    ])\n","    \n","    image_tensor = transform(image).unsqueeze(0)  # Adding batch dimension\n","    return image_tensor"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T06:53:08.206758Z","iopub.status.busy":"2023-12-04T06:53:08.205859Z","iopub.status.idle":"2023-12-04T06:53:08.230295Z","shell.execute_reply":"2023-12-04T06:53:08.229200Z","shell.execute_reply.started":"2023-12-04T06:53:08.206723Z"},"trusted":true},"outputs":[],"source":["# Time to test\n","image_path = \"/kaggle/input/combined-all-data/Data/MED/Test_Images/synpic54082.jpg\"\n","image_tensor = preprocess_image(image_path)\n","\n","# Tokenize the Question\n","question = \"Which modality is displayed?\"\n","inputs = tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True)\n","inputs = {key: val.to(device) for key, val in inputs.items()}"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T06:53:08.519038Z","iopub.status.busy":"2023-12-04T06:53:08.518680Z","iopub.status.idle":"2023-12-04T06:53:09.558116Z","shell.execute_reply":"2023-12-04T06:53:09.556943Z","shell.execute_reply.started":"2023-12-04T06:53:08.519010Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]}],"source":["# Model Inference\n","with torch.no_grad():\n","    image_tensor = image_tensor.to(device)\n","    generated_ids = peft_model.generate(input_ids=inputs[\"input_ids\"].to(device), \n","                                   attention_mask=inputs[\"attention_mask\"].to(device), \n","                                   pixel_values=image_tensor)"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T06:53:18.240468Z","iopub.status.busy":"2023-12-04T06:53:18.240056Z","iopub.status.idle":"2023-12-04T06:53:18.248542Z","shell.execute_reply":"2023-12-04T06:53:18.247423Z","shell.execute_reply.started":"2023-12-04T06:53:18.240434Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Which modality is displayed?\n","ct\n"]}],"source":["# Decode the Answer\n","predicted_answer = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","\n","print(question)\n","print(predicted_answer)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T07:08:25.283677Z","iopub.status.busy":"2023-12-04T07:08:25.283234Z","iopub.status.idle":"2023-12-04T07:08:25.331253Z","shell.execute_reply":"2023-12-04T07:08:25.330136Z","shell.execute_reply.started":"2023-12-04T07:08:25.283644Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(tensor([[[-1.6609, -1.6609, -1.6463,  ..., -1.5879, -1.5733, -1.5879],\n","          [-1.6609, -1.6463, -1.6463,  ..., -1.5879, -1.5733, -1.5879],\n","          [-1.6463, -1.6463, -1.6317,  ..., -1.5879, -1.5733, -1.5879],\n","          ...,\n","          [-1.7777, -1.7777, -1.7777,  ..., -1.7777, -1.7777, -1.7777],\n","          [-1.7777, -1.7777, -1.7777,  ..., -1.7777, -1.7777, -1.7777],\n","          [-1.7777, -1.7777, -1.7777,  ..., -1.7777, -1.7777, -1.7777]],\n"," \n","         [[-1.6170, -1.6170, -1.6020,  ..., -1.5420, -1.5270, -1.5420],\n","          [-1.6170, -1.6020, -1.6020,  ..., -1.5420, -1.5270, -1.5420],\n","          [-1.6020, -1.6020, -1.5870,  ..., -1.5420, -1.5270, -1.5420],\n","          ...,\n","          [-1.7371, -1.7371, -1.7371,  ..., -1.7371, -1.7371, -1.7371],\n","          [-1.7371, -1.7371, -1.7371,  ..., -1.7371, -1.7371, -1.7371],\n","          [-1.7371, -1.7371, -1.7371,  ..., -1.7371, -1.7371, -1.7371]],\n"," \n","         [[-1.3522, -1.3522, -1.3380,  ..., -1.2811, -1.2669, -1.2811],\n","          [-1.3522, -1.3380, -1.3380,  ..., -1.2811, -1.2669, -1.2811],\n","          [-1.3380, -1.3380, -1.3238,  ..., -1.2811, -1.2669, -1.2811],\n","          ...,\n","          [-1.4660, -1.4660, -1.4660,  ..., -1.4660, -1.4660, -1.4660],\n","          [-1.4660, -1.4660, -1.4660,  ..., -1.4660, -1.4660, -1.4660],\n","          [-1.4660, -1.4660, -1.4660,  ..., -1.4660, -1.4660, -1.4660]]]),\n"," 'is this an axial plane',\n"," 'yes')"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["test_dataset = VQAMedDataset(\"/kaggle/input/test-text/vqa_rad_test_converted.txt\", \"/kaggle/input/combined-all-data/Data/RAD/Images\", transform=transform)\n","test_data_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n","\n","test_dataset[0]"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T07:08:36.057422Z","iopub.status.busy":"2023-12-04T07:08:36.057054Z","iopub.status.idle":"2023-12-04T07:08:47.669441Z","shell.execute_reply":"2023-12-04T07:08:47.668223Z","shell.execute_reply.started":"2023-12-04T07:08:36.057391Z"},"trusted":true},"outputs":[],"source":["def predict_answers(model, data_loader, device):\n","    model.eval()\n","    predictions = []\n","    with torch.no_grad():\n","        for images, questions, _ in data_loader:\n","            inputs = tokenizer(questions, return_tensors=\"pt\", padding=True, truncation=True)\n","            images = images.to(device)\n","            inputs = {key: val.to(device) for key, val in inputs.items()}\n","            \n","            outputs = model.generate(pixel_values=images, input_ids=inputs[\"input_ids\"])\n","            decoded_predictions = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n","            predictions.extend(decoded_predictions)\n","    return predictions\n","\n","predicted_answers = predict_answers(peft_model, test_data_loader, device)"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T07:08:51.182946Z","iopub.status.busy":"2023-12-04T07:08:51.182168Z","iopub.status.idle":"2023-12-04T07:08:51.189393Z","shell.execute_reply":"2023-12-04T07:08:51.188322Z","shell.execute_reply.started":"2023-12-04T07:08:51.182913Z"},"trusted":true},"outputs":[],"source":["def classify_answer(answer):\n","    return 'OPEN' if answer.lower() not in ['yes', 'no'] else 'CLOSED'\n","\n","predicted_answer_types = [classify_answer(ans) for ans in predicted_answers]"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T07:09:24.452021Z","iopub.status.busy":"2023-12-04T07:09:24.451624Z","iopub.status.idle":"2023-12-04T07:09:24.468711Z","shell.execute_reply":"2023-12-04T07:09:24.467755Z","shell.execute_reply.started":"2023-12-04T07:09:24.451988Z"},"trusted":true},"outputs":[],"source":["ground_truth = []\n","with open(\"/kaggle/input/combined-all-data/Data/RAD/rad_test.txt\", 'r', encoding=\"utf-8\") as file:\n","    for line in file:\n","        _, _, _, answer_type = line.strip().split('|')\n","        ground_truth.append(answer_type)"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T07:09:32.995117Z","iopub.status.busy":"2023-12-04T07:09:32.994723Z","iopub.status.idle":"2023-12-04T07:09:33.010259Z","shell.execute_reply":"2023-12-04T07:09:33.008877Z","shell.execute_reply.started":"2023-12-04T07:09:32.995086Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Open Accuracy: 0.9876543209876543\n","Closed Accuracy: 0.8611111111111112\n","Overall Accuracy: 0.9066666666666666\n"]}],"source":["open_accuracy = accuracy_score(\n","    [gt for gt, pred in zip(ground_truth, predicted_answer_types) if gt == 'OPEN'],\n","    [pred for gt, pred in zip(ground_truth, predicted_answer_types) if gt == 'OPEN']\n",")\n","closed_accuracy = accuracy_score(\n","    [gt for gt, pred in zip(ground_truth, predicted_answer_types) if gt == 'CLOSED'],\n","    [pred for gt, pred in zip(ground_truth, predicted_answer_types) if gt == 'CLOSED']\n",")\n","overall_accuracy = accuracy_score(ground_truth, predicted_answer_types)\n","\n","print(f\"Open Accuracy: {open_accuracy}\")\n","print(f\"Closed Accuracy: {closed_accuracy}\")\n","print(f\"Overall Accuracy: {overall_accuracy}\")"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T07:12:20.659739Z","iopub.status.busy":"2023-12-04T07:12:20.658957Z","iopub.status.idle":"2023-12-04T07:12:22.320641Z","shell.execute_reply":"2023-12-04T07:12:22.319359Z","shell.execute_reply.started":"2023-12-04T07:12:20.659707Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["# To login in HF\n","!huggingface-cli login --token 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"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T07:12:56.323508Z","iopub.status.busy":"2023-12-04T07:12:56.322500Z","iopub.status.idle":"2023-12-04T07:15:47.064942Z","shell.execute_reply":"2023-12-04T07:15:47.063903Z","shell.execute_reply.started":"2023-12-04T07:12:56.323454Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"130ffe63b49c4900a1032bd88d9706b8","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.54G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/dineshcr7/Final-BLIP-LORA/commit/29c02628a2b8b3e2740a450f6fd6dd7f87a352b6', commit_message='Upload processor', commit_description='', oid='29c02628a2b8b3e2740a450f6fd6dd7f87a352b6', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["# Push the model in HF\n","model.push_to_hub(\"Final-BLIP-LORA\")\n","tokenizer.push_to_hub(\"Final-BLIP-LORA\")\n","processor.push_to_hub(\"Final-BLIP-LORA\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4045643,"sourceId":7033108,"sourceType":"datasetVersion"},{"datasetId":4102556,"sourceId":7114230,"sourceType":"datasetVersion"},{"datasetId":4102939,"sourceId":7114729,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
